{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import imageio, os, glob\n",
    "import cv2\n",
    "import random as rn\n",
    "\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed values \n",
    "np.random.seed(30)\n",
    "rn.seed(30)\n",
    "tf.random.set_seed(30)\n",
    "seed = 30\n",
    "\n",
    "# set batch size for image processing\n",
    "BATCH_SIZE = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Images path and getting image names\n",
    "T1_image_path = '/Users/chetansehgal/Documents/Upgrad/9. Capstone/Project/MRI Dataset/Tr1/TrainT1/'\n",
    "T2_image_path = '/Users/chetansehgal/Documents/Upgrad/9. Capstone/Project/MRI Dataset/Tr2/TrainT2/'\n",
    "\n",
    "T1_image_names = os.listdir(T1_image_path)\n",
    "T2_image_names = os.listdir(T2_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing a sample image\n",
    "img_T1 = cv2.imread(T1_image_path+T1_image_names[0])\n",
    "img_T2 = cv2.imread(T2_image_path+T2_image_names[0])\n",
    "\n",
    "plt.figure(figsize=(10,12))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('T1 Image', fontsize=16, fontweight='bold')\n",
    "plt.axis('off')\n",
    "plt.imshow(img_T1, cmap='gray')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('T2 Image', fontsize=16, fontweight='bold')\n",
    "plt.axis('off')\n",
    "plt.imshow(img_T2, cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Image loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing, resizing and loading the images\n",
    "\n",
    "T1_data = np.zeros((len(T1_image_names), 128, 128, 3))\n",
    "T2_data = np.zeros((len(T2_image_names), 128, 128, 3))\n",
    "\n",
    "for index, img in enumerate(T1_image_names):\n",
    "    imgT1 = cv2.imread(T1_image_path+img)\n",
    "    imgT1 = cv2.cvtColor(imgT1, cv2.COLOR_BGR2RGB)\n",
    "    imgT1 = (imgT1/127.5)-1.0                           # Normalize the image to [-1.0, 1.0]\n",
    "    T1_data[index, :, :, :] = resize(imgT1, (128, 128)) # resizing the image\n",
    "    \n",
    "for index, img in enumerate(T2_image_names):\n",
    "    imgT2 = cv2.imread(T2_image_path+img)\n",
    "    imgT2 = cv2.cvtColor(imgT2, cv2.COLOR_BGR2RGB)\n",
    "    imgT2 = (imgT2/127.5)-1.0                            # Normalize the image to [-1.0, 1.0]\n",
    "    T2_data[index, :, :, :] = resize(imgT2, (128, 128))  # resizing the image\n",
    "\n",
    "# changing dtype to float32\n",
    "T1_data = T1_data.astype('float32')\n",
    "T2_data = T2_data.astype('float32')\n",
    "\n",
    "print(f'T1 shape: {T1_data.shape}')\n",
    "print(f'T2 shape: {T2_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# checking normalized sample\n",
    "T1_data[1,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating batch and shuffling data\n",
    "\n",
    "T1_data_batch = tf.data.Dataset.from_tensor_slices(T1_data).shuffle(T1_data.shape[0], seed=seed).batch(BATCH_SIZE)\n",
    "T2_data_batch = tf.data.Dataset.from_tensor_slices(T2_data).shuffle(T2_data.shape[0], seed=seed).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing a sample\n",
    "\n",
    "sample_T1_data = next(iter(T1_data_batch))\n",
    "sample_T2_data = next(iter(T2_data_batch))\n",
    "\n",
    "plt.figure(figsize=(10, 12))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(sample_T1_data[0, :, :, 0], cmap='gray')\n",
    "plt.title('T1_data')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(sample_T2_data[0, :, :, 0], cmap='gray')\n",
    "plt.title('T2_data')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building generator and discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instance Normalization\n",
    "class InstanceNormalization(tf.keras.layers.Layer):\n",
    "    # Initialization of Objects\n",
    "    def __init__(self, epsilon=1e-5):\n",
    "        # calling parent's init\n",
    "        super(InstanceNormalization, self).__init__()\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.scale = self.add_weight(\n",
    "            name='scale',\n",
    "            shape=input_shape[-1:],\n",
    "            initializer=tf.random_normal_initializer(1., 0.02),\n",
    "            trainable=True)\n",
    "        self.offset = self.add_weight(\n",
    "            name='offset',\n",
    "            shape=input_shape[-1:],\n",
    "            initializer='zeros',\n",
    "            trainable=True)\n",
    "    \n",
    "    def call(self, x):\n",
    "        # Compute Mean and Variance, Axes=[1,2] ensures Instance Normalization\n",
    "        mean, variance = tf.nn.moments(x, axes=[1, 2], keepdims=True)\n",
    "        inv = tf.math.rsqrt(variance + self.epsilon)\n",
    "        normalized = (x - mean) * inv\n",
    "        return self.scale * normalized + self.offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsampling is performed using the Convolution, leading to reduce in dimensions.\n",
    "def downsample(filters, size, apply_norm=True):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    result = tf.keras.Sequential()\n",
    "    # Add Conv2d layer\n",
    "    result.add(tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
    "                                      kernel_initializer=initializer, use_bias=False))\n",
    "    # Add Normalization layer\n",
    "    if apply_norm:\n",
    "        result.add(InstanceNormalization())\n",
    "    # Add Leaky Relu Activation\n",
    "    result.add(tf.keras.layers.LeakyReLU())\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsampling is a result of Transposed Convolution, where dimension of image are increased.\n",
    "def upsample(filters, size, apply_dropout=False):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    result = tf.keras.Sequential()\n",
    "    # Add Transposed Conv2d layer\n",
    "    result.add(tf.keras.layers.Conv2DTranspose(filters, size, strides=2, padding='same',\n",
    "                                               kernel_initializer=initializer, use_bias=False))\n",
    "    # Add Normalization Layer\n",
    "    result.add(InstanceNormalization())\n",
    "    # Conditionally add Dropout layer\n",
    "    if apply_dropout:\n",
    "        result.add(tf.keras.layers.Dropout(0.5))\n",
    "    # Add Relu Activation Layer\n",
    "    result.add(tf.keras.layers.ReLU())\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unet Generator is a combination of Convolution + Transposed Convolution Layers\n",
    "def unet_generator():\n",
    "    down_stack = [\n",
    "        downsample(64, 4, False), # (bs, 64, 64, 64)\n",
    "        downsample(128, 4), # (bs, 32, 32, 128)\n",
    "        downsample(128, 4), # (bs, 16, 16, 128)\n",
    "        downsample(128, 4), # (bs, 8, 8, 128)\n",
    "        downsample(128, 4), # (bs, 4, 4, 128)\n",
    "        downsample(128, 4), # (bs, 2, 2, 128)\n",
    "        downsample(128, 4) # (bs, 1, 1, 128)\n",
    "    ]\n",
    "    up_stack = [\n",
    "        upsample(128, 4, True), # (bs, 2, 2, 256)\n",
    "        upsample(128, 4, True), # (bs, 4, 4, 256)\n",
    "        upsample(128, 4, True), # (bs, 8, 8, 256)\n",
    "        upsample(128, 4, True), # (bs, 16, 16, 256)\n",
    "        upsample(128, 4), # (bs, 32, 32, 256)\n",
    "        upsample(64, 4) # (bs, 64, 64, 64)\n",
    "    ]\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    last = tf.keras.layers.Conv2DTranspose(3, 4, strides=2, padding='same', kernel_initializer=initializer,\n",
    "                                           activation='tanh') # (bs, 128, 128, 3)\n",
    "    concat = tf.keras.layers.Concatenate()\n",
    "    inputs = tf.keras.layers.Input(shape=[128, 128, 3])\n",
    "    x = inputs\n",
    "    # Downsampling through the model\n",
    "    skips = []\n",
    "    for down in down_stack:\n",
    "        x = down(x)\n",
    "        skips.append(x)\n",
    "    \n",
    "    skips = reversed(skips[:-1])\n",
    "    # Upsampling and establishing the skip connections\n",
    "    for up, skip in zip(up_stack, skips):\n",
    "        x = up(x)\n",
    "        x = concat([x, skip])\n",
    "    x = last(x)\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing generator T1_T2/ T2_T1\n",
    "generator_T1_T2 = unet_generator()\n",
    "generator_T2_T1 = unet_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_T2_T1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminators only contain Convolutional Layers and no Transposed Convolution is not used \n",
    "def discriminator():\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    # add input layer of size (128, 128, 3)\n",
    "    inp = tf.keras.layers.Input(shape=[128, 128, 3], name='input_image')\n",
    "    x = inp\n",
    "    \n",
    "    # add downsampling step here\n",
    "    down1 = downsample(64, 4, False)(x) # (bs, 64, 64, 64)\n",
    "    down2 = downsample(128, 4)(down1) # (bs, 32, 32, 128)\n",
    "    down3 = downsample(128, 4)(down2)\n",
    "    down4 = downsample(128, 4)(down3)\n",
    "    # add a padding layer here\n",
    "    zero_pad1 = tf.keras.layers.ZeroPadding2D()(down4) # (bs, 10, 10, 128)\n",
    "    \n",
    "    # implement a concrete downsampling layer here\n",
    "    conv = tf.keras.layers.Conv2D(256, 4, strides=1, kernel_initializer=initializer,\n",
    "                                  use_bias=False)(zero_pad1) # (bs, 7, 7, 256)\n",
    "    norm1 = InstanceNormalization()(conv)\n",
    "    leaky_relu = tf.keras.layers.LeakyReLU()(norm1)\n",
    "    \n",
    "    # apply zero padding layer\n",
    "    zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu) # (bs, 9, 9, 256)\n",
    "    \n",
    "    # add a last pure 2D Convolution layer\n",
    "    last = tf.keras.layers.Conv2D(1, 4, strides=1, kernel_initializer=initializer)(zero_pad2) # (bs, 6, 6, 1)\n",
    "    return tf.keras.Model(inputs=inp, outputs=last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_x = discriminator()\n",
    "discriminator_y = discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_x.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# untrained generator images check\n",
    "\n",
    "T1T2_data = generator_T1_T2(sample_T1_data)\n",
    "T2T1_data = generator_T2_T1(sample_T2_data)\n",
    "plt.figure(figsize=(4, 4))\n",
    "\n",
    "imgs = [sample_T1_data, T1T2_data, sample_T2_data, T2T1_data]\n",
    "title = ['Sample_T1_data', 'T1T2_data', 'Sample_T2_data', 'T2T1_data']\n",
    "\n",
    "plt.figure(figsize=(8,10))\n",
    "for i in range(len(imgs)):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.title(title[i])\n",
    "    plt.imshow(imgs[i][0].numpy()[:, :, 0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting loss functions\n",
    "\n",
    "loss_obj = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(real, generated):\n",
    "    real_loss = loss_obj(tf.ones_like(real), real)\n",
    "    generated_loss = loss_obj(tf.zeros_like(generated), generated)\n",
    "    total_disc_loss = real_loss + generated_loss\n",
    "    return total_disc_loss * 0.5 # mean of losses\n",
    "\n",
    "def generator_loss(generated):\n",
    "    return loss_obj(tf.ones_like(generated), generated)\n",
    "\n",
    "def calc_cycle_loss(real_image, cycled_image):\n",
    "    loss1 = tf.reduce_mean(tf.abs(real_image - cycled_image))\n",
    "    return 10.0 * loss1\n",
    "\n",
    "def identity_loss(real_image, same_image):\n",
    "    loss = tf.reduce_mean(tf.abs(real_image - same_image))\n",
    "    return 0.5*loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 300\n",
    "\n",
    "generator_T1_T2_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "generator_T2_T1_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "discriminator_x_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_y_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkpoint Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"/Users/chetansehgal/Documents/Upgrad/9. Capstone/Project/MRI Dataset/Checkpoint\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(generator_T1_T2=generator_T1_T2,\n",
    "                           generator_T2_T1=generator_T2_T1,\n",
    "                           discriminator_x=discriminator_x,\n",
    "                           discriminator_y=discriminator_y,\n",
    "                           generator_T1_T2_optimizer=generator_T1_T2_optimizer,\n",
    "                           generator_T2_T1_optimizer=generator_T2_T1_optimizer,\n",
    "                           discriminator_x_optimizer=discriminator_x_optimizer,\n",
    "                           discriminator_y_optimizer=discriminator_y_optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=3)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to show Images output by Generators while Training\n",
    "def generate_images(model1, test_input1, model2, test_input2):\n",
    "    prediction1 = model1(test_input1)\n",
    "    prediction2 = model2(test_input2)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    display_list = [test_input1[0], prediction1[0], test_input2[0], prediction2[0]]\n",
    "    title = ['Input Image', 'Predicted Image', 'Input Image', 'Predicted Image']\n",
    "    for i in range(4):\n",
    "        plt.subplot(1, 4, i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(display_list[i].numpy()[:, :, 0], cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(real_x, real_y):\n",
    "    # persistent is set to True because the tape is used more than\n",
    "    # once to calculate the gradients.\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        # Generator G translates X -> Y\n",
    "        # Generator F translates Y -> X\n",
    "        fake_y = generator_T1_T2(real_x, training=True)\n",
    "        fake_x = generator_T2_T1(real_y, training=True)\n",
    "      \n",
    "        cycled_y = generator_T1_T2(fake_x, training=True)\n",
    "        cycled_x = generator_T2_T1(fake_y, training=True)\n",
    "        \n",
    "        # same_x and same_y are used for identity loss.\n",
    "        same_x = generator_T2_T1(real_x, training=True)\n",
    "        same_y = generator_T1_T2(real_y, training=True)\n",
    "        \n",
    "        disc_real_x = discriminator_x(real_x, training=True)\n",
    "        disc_real_y = discriminator_y(real_y, training=True)\n",
    "        \n",
    "        disc_fake_x = discriminator_x(fake_x, training=True)\n",
    "        disc_fake_y = discriminator_y(fake_y, training=True)\n",
    "        \n",
    "        # calculate the loss\n",
    "        gen_T1_T2_loss = generator_loss(disc_fake_y)\n",
    "        gen_T2_T1_loss = generator_loss(disc_fake_x)\n",
    "        \n",
    "        total_cycle_loss = calc_cycle_loss(real_x, cycled_x) + calc_cycle_loss(real_y, cycled_y)\n",
    "        \n",
    "        # Total generator loss = BCE loss + cycle loss + identity loss\n",
    "        total_gen_T1_T2_loss = gen_T1_T2_loss + total_cycle_loss + identity_loss(real_y, same_y)\n",
    "        total_gen_T2_T1_loss = gen_T2_T1_loss + total_cycle_loss + identity_loss(real_x, same_x)\n",
    "        \n",
    "        # Discriminator's loss\n",
    "        disc_x_loss = discriminator_loss(disc_real_x, disc_fake_x)\n",
    "        disc_y_loss = discriminator_loss(disc_real_y, disc_fake_y)\n",
    "        \n",
    "    # Calculate the gradients for generator and discriminator\n",
    "    generator_T1_T2_gradients = tape.gradient(total_gen_T1_T2_loss, generator_T1_T2.trainable_variables)\n",
    "    generator_T2_T1_gradients = tape.gradient(total_gen_T2_T1_loss, generator_T2_T1.trainable_variables)\n",
    "    \n",
    "    discriminator_x_gradients = tape.gradient(disc_x_loss, discriminator_x.trainable_variables)\n",
    "    discriminator_y_gradients = tape.gradient(disc_y_loss, discriminator_y.trainable_variables)\n",
    "    \n",
    "    # Apply the gradients to the optimizer\n",
    "    generator_T1_T2_optimizer.apply_gradients(zip(generator_T1_T2_gradients, generator_T1_T2.trainable_variables))\n",
    "    generator_T2_T1_optimizer.apply_gradients(zip(generator_T2_T1_gradients, generator_T2_T1.trainable_variables))\n",
    "    \n",
    "    discriminator_x_optimizer.apply_gradients(zip(discriminator_x_gradients, discriminator_x.trainable_variables))\n",
    "    discriminator_y_optimizer.apply_gradients(zip(discriminator_y_gradients, discriminator_y.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training the model\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    for image_x, image_y in tf.data.Dataset.zip((T1_data_batch, T2_data_batch)):\n",
    "        train_step(image_x, image_y)\n",
    "    generate_images(generator_T1_T2, sample_T1_data, generator_T2_T1, sample_T2_data)\n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    print('Saving checkpoint for epoch', epoch, 'at', ckpt_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating animation for displaying per epoch changes\n",
    "anim_file = 'cyclegan.gif'\n",
    "\n",
    "with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "  filenames = glob.glob('image*.png')\n",
    "  filenames = sorted(filenames)\n",
    "  for filename in filenames:\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)\n",
    "  image = imageio.imread(filename)\n",
    "  writer.append_data(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# displaying gif animation using tensorflow docs\n",
    "pip install git+https://github.com/tensorflow/docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# displaying gif animation using tensorflow docs\n",
    "import tensorflow_docs.vis.embed as embed\n",
    "embed.embed_file(anim_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
